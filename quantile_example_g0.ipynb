{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f2d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from enum import Enum\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45b19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance labels\n",
    "class Distance(Enum):\n",
    "    CVM = 0 # ABC-CvM\n",
    "    MMD = 1 # ABC-MMD\n",
    "    WASS = 2 # ABC-Wass\n",
    "    STAT = 3  # ABC-Stat\n",
    "\n",
    "DISTANCE_LABELS = {Distance.CVM: \"CvM\", Distance.MMD: \"MMD\", Distance.WASS: \"Wass\", Distance.STAT: \"Stat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute the distance metrics\n",
    "\n",
    "# Common to all examples\n",
    "def cramer_von_mises_distance(obs, sim):\n",
    "    n = len(obs)\n",
    "    m = len(sim)\n",
    "    combined = np.concatenate((obs, sim))\n",
    "    ranks = rankdata(combined)\n",
    "    obs_ranks = np.sort(ranks[:n])\n",
    "    sim_ranks = np.sort(ranks[n:])\n",
    "    i = np.arange(1, n + 1)\n",
    "    j = np.arange(1, m + 1)\n",
    "    term1 = n * np.sum((obs_ranks - i) ** 2)\n",
    "    term2 = m * np.sum((sim_ranks - j) ** 2)\n",
    "    denom = n * m * (n + m)\n",
    "    distance = (term1 + term2) / denom - (4 * n * m - 1) / (6 * (n + m))\n",
    "    return distance\n",
    "\n",
    "# Common to all examples\n",
    "def wasserstein_distance(obs, sim):\n",
    "    if len(obs) == len(sim):\n",
    "        sorted_obs = np.sort(obs)\n",
    "        sorted_sim = np.sort(sim)\n",
    "        return np.mean(np.abs(sorted_obs - sorted_sim))\n",
    "    else:\n",
    "        # fallback to scipy implementation if different sizes\n",
    "        from scipy.stats import wasserstein_distance as ws\n",
    "        return ws(obs, sim)\n",
    "\n",
    "# Common to all examples\n",
    "def gaussian_kernel(sq_distances, sigma):\n",
    "    return np.exp(-sq_distances / (2 * sigma))\n",
    "\n",
    "# Common to all examples\n",
    "def maximum_mean_discrepancy(obs, sim, obs_sq_dist=None, sigma=None):\n",
    "    if obs_sq_dist is None:\n",
    "        obs_sq_dist = pdist(obs.reshape(-1,1), 'sqeuclidean')\n",
    "    if sigma is None:\n",
    "        sigma = np.median(obs_sq_dist) ** 0.5\n",
    "    sim_sq_dist = pdist(sim.reshape(-1,1), 'sqeuclidean')\n",
    "    mixed_sq_dist = cdist(obs.reshape(-1,1), sim.reshape(-1,1), 'sqeuclidean')\n",
    "    k_xx = np.mean(gaussian_kernel(obs_sq_dist, sigma))\n",
    "    k_yy = np.mean(gaussian_kernel(sim_sq_dist, sigma))\n",
    "    k_xy = np.mean(gaussian_kernel(mixed_sq_dist, sigma))\n",
    "    return k_xx + k_yy - 2 * k_xy\n",
    "\n",
    "# Function specific for the quantile distribution example for ABC-Stat\n",
    "def stat_distance(obs, sim):\n",
    "    # Compute 0.1 and 0.9 quantiles for both datasets\n",
    "    obs_q = np.quantile(obs, [0.1, 0.9])\n",
    "    sim_q = np.quantile(sim, [0.1, 0.9])\n",
    "    \n",
    "    # Compute L1 norm (sum of absolute differences)\n",
    "    return np.sum(np.abs(obs_q - sim_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0497f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile function for the g-and-k distribution\n",
    "def g_and_k_quantile(z, A=0, B=1, g=0, k=0, c=0.8):\n",
    "    term1 = (1 + c * (1 - np.exp(-g * z)) / (1 + np.exp(-g * z)))\n",
    "    term2 = (1 + z**2) ** k\n",
    "    return A + B * term1 * term2 * z\n",
    "\n",
    "# Function to generate simulated datasets. We generate the same number of simulated datasets.\n",
    "def simulate_datasets(n_sim=10**3, sample_size=100):\n",
    "    half = n_sim // 2\n",
    "    A = 0\n",
    "    B = 1\n",
    "    c = 0.8\n",
    "\n",
    "    # Model 0: g = 0, k ~ Uniform(-0.5, 5)\n",
    "    k0 = np.random.uniform(-0.5, 5, size=half)\n",
    "    g0 = np.zeros(half)\n",
    "    models0 = np.zeros(half, dtype=int)\n",
    "    z0 = np.random.normal(0, 1, size=(half, sample_size))\n",
    "    sim0 = np.array([\n",
    "        g_and_k_quantile(z0[i], A=A, B=B, g=g0[i], k=k0[i], c=c)\n",
    "        for i in range(half)\n",
    "    ])\n",
    "    \n",
    "    # Model 1: g ~ Uniform(0, 4), k ~ Uniform(-0.5, 5)\n",
    "    g1 = np.random.uniform(0, 4, size=half)\n",
    "    k1 = np.random.uniform(-0.5, 5, size=half)\n",
    "    models1 = np.ones(half, dtype=int)\n",
    "    z1 = np.random.normal(0, 1, size=(half, sample_size))\n",
    "    sim1 = np.array([\n",
    "        g_and_k_quantile(z1[i], A=A, B=B, g=g1[i], k=k1[i], c=c)\n",
    "        for i in range(half)\n",
    "    ])\n",
    "\n",
    "    # Combine datasets\n",
    "    sims = np.vstack((sim0, sim1))\n",
    "    g_values = np.concatenate((g0, g1))\n",
    "    k_values = np.concatenate((k0, k1))\n",
    "    models = np.concatenate((models0, models1))\n",
    "\n",
    "    thetas = np.vstack((g_values, k_values)).T\n",
    "\n",
    "    return sims, thetas, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances for one observed sample\n",
    "def compute_distances(observed_sample, sims):\n",
    "    n_sim = sims.shape[0]\n",
    "    sample_size = len(observed_sample)\n",
    "    \n",
    "    # Precompute squared distances and sigma for MMD\n",
    "    obs_sq_dist = pdist(observed_sample.reshape(-1,1), 'sqeuclidean')\n",
    "    sigma = np.median(obs_sq_dist) ** 0.5\n",
    "    \n",
    "    distances_cvm = np.zeros(n_sim)\n",
    "    distances_wass = np.zeros(n_sim)\n",
    "    distances_mmd = np.zeros(n_sim)\n",
    "    distances_stat = np.zeros(n_sim)\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        sim_sample = sims[i]\n",
    "        distances_cvm[i] = cramer_von_mises_distance(observed_sample, sim_sample)\n",
    "        distances_wass[i] = wasserstein_distance(observed_sample, sim_sample)\n",
    "        distances_mmd[i] = maximum_mean_discrepancy(observed_sample, sim_sample, obs_sq_dist, sigma)\n",
    "        distances_stat[i] = stat_distance(observed_sample, sim_sample)\n",
    "    \n",
    "    return distances_cvm, distances_mmd, distances_wass, distances_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99130949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize lowest percentile\n",
    "def summarize_percentile(thetas, models, distances, percentile):\n",
    "    n = len(distances)\n",
    "    n_keep = max(1, round(n * percentile / 100))\n",
    "    indices = np.argsort(distances)[:n_keep]\n",
    "\n",
    "    selected_thetas = thetas[indices]\n",
    "    selected_models = models[indices]\n",
    "\n",
    "    # Find the most frequently selected model\n",
    "    if len(selected_models) == 0:\n",
    "        return np.nan, np.array([np.nan, np.nan])\n",
    "\n",
    "    values, counts = np.unique(selected_models, return_counts=True)\n",
    "    most_common_model = values[np.argmax(counts)]\n",
    "\n",
    "    # Compute proportion of most common model\n",
    "    prop_common_model = np.mean(selected_models == most_common_model)\n",
    "\n",
    "    # Average theta only from simulations matching the most common model\n",
    "    theta_subset = selected_thetas[selected_models == most_common_model]\n",
    "    mean_theta = np.mean(theta_subset, axis=0) if len(theta_subset) > 0 else np.array([np.nan, np.nan])\n",
    "\n",
    "    return prop_common_model, mean_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24747310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ABC for one observed dataset\n",
    "def run_abc_for_one_observed(args):\n",
    "    observed_sample, sims, thetas, models, percentiles = args\n",
    "    dist_cvm, dist_mmd, dist_wass, dist_stat = compute_distances(observed_sample, sims)\n",
    "    \n",
    "    results = {}\n",
    "    for dist_enum, dist_array in zip(Distance, [dist_cvm, dist_mmd, dist_wass, dist_stat]):\n",
    "        dist_name = DISTANCE_LABELS[dist_enum]\n",
    "        results[dist_name] = {\n",
    "            'prop_model': [],\n",
    "            'mean_theta': []  \n",
    "        }\n",
    "        for perc in percentiles:\n",
    "            prop, mean_theta = summarize_percentile(thetas, models, dist_array, perc)\n",
    "            results[dist_name]['prop_model'].append(prop)\n",
    "            results[dist_name]['mean_theta'].append(mean_theta)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c150d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating datasets...\n",
      "Simulating 10 observed datasets from g-and-k with g=0, k=2...\n",
      "Starting parallel ABC with 8 cores...\n",
      "ABC summaries saved to gk_example_results.npz\n"
     ]
    }
   ],
   "source": [
    "def g_and_k_quantile(z, A=0, B=1, c=0.8, g=0, k=2):\n",
    "    return A + B * (1 + c * np.tanh(g * z / 2)) * z * (1 + z**2)**k\n",
    "\n",
    "def sample_g_and_k(n, A=0, B=1, c=0.8, g=0, k=2):\n",
    "    z = np.random.normal(0, 1, size=n)\n",
    "    return g_and_k_quantile(z, A=A, B=B, c=c, g=g, k=k)\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    sample_size = 100\n",
    "    n_sim = 10**6\n",
    "    n_observed = 100\n",
    "    percentiles = [0.1, 0.05, 0.01] # Change this to the percentile of interest\n",
    "\n",
    "    print(\"Simulating datasets...\")\n",
    "    sims, thetas, models = simulate_datasets(n_sim=n_sim, sample_size=sample_size)\n",
    "\n",
    "    print(f\"Simulating {n_observed} observed datasets from g-and-k with g=0, k=2...\") # Simulations from model M1 (with no skewness)\n",
    "    observed_datasets = [sample_g_and_k(sample_size, A=0, B=1, c=0.8, g=0, k=2)\n",
    "                         for _ in range(n_observed)]\n",
    "\n",
    "    # Prepare arguments for parallel execution\n",
    "    args_list = [(obs, sims, thetas, models, percentiles) for obs in observed_datasets]\n",
    "\n",
    "    print(f\"Starting parallel ABC with {cpu_count()} cores...\")\n",
    "    from multiprocessing import Pool\n",
    "    with Pool() as pool:\n",
    "        all_results = pool.map(run_abc_for_one_observed, args_list)\n",
    "\n",
    "    # Initialize result containers\n",
    "    distance_names = list(DISTANCE_LABELS.values())\n",
    "    n_dist = len(distance_names)\n",
    "    n_perc = len(percentiles)\n",
    "\n",
    "    prop_model_summary = np.zeros((n_observed, n_dist, n_perc))\n",
    "    mean_theta_summary = np.zeros((n_observed, n_dist, n_perc, 2))  # For [g, k]\n",
    "\n",
    "    for i, res in enumerate(all_results):\n",
    "        for d_idx, dist_name in enumerate(distance_names):\n",
    "            prop_model_summary[i, d_idx, :] = res[dist_name]['prop_model']\n",
    "            mean_theta_summary[i, d_idx, :, :] = res[dist_name]['mean_theta']\n",
    "\n",
    "    # Save results\n",
    "    np.savez('gk_example_g0.npz',\n",
    "             prop_model=prop_model_summary,\n",
    "             mean_theta=mean_theta_summary,\n",
    "             percentiles=percentiles,\n",
    "             distance_names=distance_names)\n",
    "\n",
    "    print(\"ABC summaries saved to gk_example_g0.npz\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fdbab-2a5e-4baf-aa2a-e430fc7bca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
