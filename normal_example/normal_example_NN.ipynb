{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fcaebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:24:52.178376: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-10 12:24:52.178794: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-10 12:24:52.181221: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-10 12:24:52.187685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749522292.199087   10704 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749522292.202392   10704 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749522292.210987   10704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749522292.210996   10704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749522292.210997   10704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749522292.210998   10704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-10 12:24:52.213961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2587ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Simulate the Dataset\n",
    "num_datasets = 10**6  \n",
    "sample_size = 100    \n",
    "n_per_dist = num_datasets // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49561c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Generate datasets\n",
    "normal_samples_m0 = np.random.normal(loc=0, scale=1, size=(n_per_dist, sample_size))\n",
    "normal_samples_m1_1 = np.random.normal(loc=0.1, scale=1, size=(n_per_dist, sample_size))\n",
    "\n",
    "# Combine the datasets\n",
    "normal_samples = np.vstack([normal_samples_m0, normal_samples_m1_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfa03f8-6a47-483e-bebb-f3706027093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del normal_samples_m0, normal_samples_m1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d3f99f-708f-4a27-93ec-c62605b105e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "X = normal_samples\n",
    "# Normalize the data\n",
    "X = (X - np.mean(X, axis=1, keepdims=True)) / np.std(X, axis=1, keepdims=True)\n",
    "del normal_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc56b16c-b80a-4e95-b55f-be24dc8412b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563f91cf-21c6-4b7c-b794-18558dcbcd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of labels for model selection\n",
    "\n",
    "mu0_labels = np.zeros((n_per_dist, 1))\n",
    "mu1_1_labels = np.ones((n_per_dist, 1))       \n",
    "\n",
    "# Combine all labels\n",
    "y_class = np.vstack([mu0_labels, mu1_1_labels])\n",
    "\n",
    "y_class = to_categorical(y_class, num_classes=2)\n",
    "\n",
    "del mu0_labels, mu1_1_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f200005-0504-479d-8a11-d2daaeb6a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of parameter labels\n",
    "\n",
    "y_params_mu0 = np.zeros((n_per_dist, 1))\n",
    "y_params_mu1_1 = np.full((n_per_dist, 1), 0.1)\n",
    "\n",
    "y_params = np.vstack([y_params_mu0, y_params_mu1_1])\n",
    "\n",
    "y_params.shape\n",
    "\n",
    "del y_params_mu0, y_params_mu1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77699f63-7a4d-4265-b42b-f76756018507",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_class_train, y_class_test, y_params_train, y_params_test = train_test_split(\n",
    "    X, y_class, y_params, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ff24b9-06a6-4dec-be2d-7ded50d27e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 12:24:57.458439: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "### Step 4: Define the Multi-Task Model\n",
    "### Create a model with a shared base and two task-specific output layers: \n",
    "# one for classification and another for parameter estimation.\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(sample_size,))\n",
    "\n",
    "# Shared base layers\n",
    "shared = layers.Dense(128, activation='relu')(input_layer)\n",
    "shared = layers.Dense(64, activation='relu')(shared)\n",
    "\n",
    "# Classification output\n",
    "class_output = layers.Dense(2, activation='softmax', name='class_output')(shared)\n",
    "\n",
    "# Parameter estimation output\n",
    "param_output = layers.Dense(2, activation='linear', name='param_output')(shared)\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs=input_layer, outputs=[class_output, param_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96d82a8-16ce-4ce1-a32d-89b219ca0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 5: Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'class_output': 'categorical_crossentropy', 'param_output': 'mse'},\n",
    "              loss_weights={'class_output': 1.0, 'param_output': 0.5},\n",
    "              metrics={'class_output': 'accuracy', 'param_output': 'mae'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df9baff4-f47a-4293-bbb7-ff7b99b380a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - class_output_accuracy: 0.5010 - class_output_loss: 0.6951 - loss: 0.6992 - param_output_loss: 0.0082 - param_output_mae: 0.0637 - val_class_output_accuracy: 0.5001 - val_class_output_loss: 0.6937 - val_loss: 0.6949 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 2/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - class_output_accuracy: 0.4988 - class_output_loss: 0.6932 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5001 - val_class_output_loss: 0.6931 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 3/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - class_output_accuracy: 0.5007 - class_output_loss: 0.6932 - loss: 0.6944 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6931 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 4/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - class_output_accuracy: 0.4991 - class_output_loss: 0.6932 - loss: 0.6944 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5001 - val_class_output_loss: 0.6932 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 5/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - class_output_accuracy: 0.5000 - class_output_loss: 0.6932 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6932 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 6/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - class_output_accuracy: 0.4989 - class_output_loss: 0.6932 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6932 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 7/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - class_output_accuracy: 0.4991 - class_output_loss: 0.6932 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5001 - val_class_output_loss: 0.6934 - val_loss: 0.6946 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 8/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - class_output_accuracy: 0.4997 - class_output_loss: 0.6932 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6932 - val_loss: 0.6944 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 9/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - class_output_accuracy: 0.5017 - class_output_loss: 0.6932 - loss: 0.6944 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6933 - val_loss: 0.6945 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n",
      "Epoch 10/10\n",
      "\u001b[1m20000/20000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - class_output_accuracy: 0.5001 - class_output_loss: 0.6931 - loss: 0.6943 - param_output_loss: 0.0025 - param_output_mae: 0.0500 - val_class_output_accuracy: 0.5000 - val_class_output_loss: 0.6933 - val_loss: 0.6945 - val_param_output_loss: 0.0025 - val_param_output_mae: 0.0500\n"
     ]
    }
   ],
   "source": [
    "### Step 6: Train the Model\n",
    "history = model.fit(X_train, {'class_output': y_class_train, 'param_output': y_params_train},\n",
    "                    epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab81438-184c-4e99-b469-8474c627fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 941us/step - class_output_accuracy: 0.4984 - class_output_loss: 0.6933 - loss: 0.6945 - param_output_loss: 0.0025 - param_output_mae: 0.0500\n",
      "Test Classification Accuracy: 0.5000\n",
      "Test Parameter Estimation MAE: 0.0500\n"
     ]
    }
   ],
   "source": [
    "### Step 7: Evaluate the Model on the Test Dataset\n",
    "results = model.evaluate(X_test, {'class_output': y_class_test, 'param_output': y_params_test})\n",
    "print(f\"Test Classification Accuracy: {results[3]:.4f}\")\n",
    "print(f\"Test Parameter Estimation MAE: {results[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525de339-d243-4166-b91c-cc98149744cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (200, 100)\n",
      "Test labels shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Prediction \n",
    "# Parameters\n",
    "sample_size = 100\n",
    "n_test_per_model = 100\n",
    "\n",
    "# Means for each model\n",
    "mu_values = [0.0, 0.1]\n",
    "\n",
    "# Generate test datasets\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for label, mu in enumerate(mu_values):\n",
    "    data = np.random.normal(loc=mu, scale=1.0, size=(n_test_per_model, sample_size))\n",
    "    test_data.append(data)\n",
    "    test_labels.append(np.full((n_test_per_model,), label))\n",
    "\n",
    "# Combine all into arrays\n",
    "X_new = np.vstack(test_data)\n",
    "y_class_new = np.concatenate(test_labels)\n",
    "\n",
    "print(\"Test data shape:\", X_new.shape)       \n",
    "print(\"Test labels shape:\", y_class_new.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e94b75-a926-41d9-a163-13fc505e66c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af8a4d0-5e73-4c0d-9f4a-2db8283691ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = predictions[0]  # shape (n_samples, 6)\n",
    "n_samples = probabilities.shape[0]\n",
    "n_classes = probabilities.shape[1]\n",
    "\n",
    "class_predictions_m0m1 = np.array([\n",
    "    np.random.choice(n_classes, p=probabilities[i])\n",
    "    for i in range(n_samples)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7aa5b24-dc15-4dbc-9fcf-03fd50b33454",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_predictions_m0m1 = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dbb58a7-0c17-4a93-ad42-48d2601872ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50 50]\n",
      " [48 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_m0m1 = confusion_matrix(y_class_new, class_predictions_m0m1)\n",
    "print(cm_m0m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad142f3f-362e-49c8-9ff7-9e2020bdd9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49659434 0.5034057 ]\n",
      " [0.49659434 0.5034057 ]\n",
      " [0.49659434 0.5034057 ]\n",
      " [0.49659434 0.5034057 ]\n",
      " [0.49659434 0.5034057 ]]\n"
     ]
    }
   ],
   "source": [
    "print(probabilities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "763daeb8-5944-4882-8bc9-317fa61cb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(probabilities[:100, 0], columns=[\"NN\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"normal_model0_NN_probabilities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd9580e-d892-4520-a1cc-9f5c97c1287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters shape: (200, 2)\n",
      "First 5 parameter estimates:\n",
      " [[0.0494449 0.0494449]\n",
      " [0.0494449 0.0494449]\n",
      " [0.0494449 0.0494449]\n",
      " [0.0494449 0.0494449]\n",
      " [0.0494449 0.0494449]]\n"
     ]
    }
   ],
   "source": [
    "params_new = predictions[1]\n",
    "print(\"Estimated parameters shape:\", params_new.shape)\n",
    "print(\"First 5 parameter estimates:\\n\", params_new[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "498aa41b-7d7e-4578-9c41-ca029ff24e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(params_new[:100, 0], columns=[\"NN\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"normal_model0_NN_params.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
