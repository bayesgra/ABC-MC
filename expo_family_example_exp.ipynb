{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f2d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from enum import Enum\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45b19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance labels\n",
    "class Distance(Enum):\n",
    "    CVM = 0 # ABC-CvM\n",
    "    MMD = 1 # ABC-MMD\n",
    "    WASS = 2 # ABC-Wass\n",
    "    STAT = 3  # ABC-Stat\n",
    "\n",
    "DISTANCE_LABELS = {Distance.CVM: \"CvM\", Distance.MMD: \"MMD\", Distance.WASS: \"Wass\", Distance.STAT: \"Stat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the distance metrics\n",
    "\n",
    "# Common to all examples\n",
    "def cramer_von_mises_distance(obs, sim):\n",
    "    n = len(obs)\n",
    "    m = len(sim)\n",
    "    combined = np.concatenate((obs, sim))\n",
    "    ranks = rankdata(combined)\n",
    "    obs_ranks = np.sort(ranks[:n])\n",
    "    sim_ranks = np.sort(ranks[n:])\n",
    "    i = np.arange(1, n + 1)\n",
    "    j = np.arange(1, m + 1)\n",
    "    term1 = n * np.sum((obs_ranks - i) ** 2)\n",
    "    term2 = m * np.sum((sim_ranks - j) ** 2)\n",
    "    denom = n * m * (n + m)\n",
    "    distance = (term1 + term2) / denom - (4 * n * m - 1) / (6 * (n + m))\n",
    "    return distance\n",
    "\n",
    "# Common to all examples\n",
    "def wasserstein_distance(obs, sim):\n",
    "    if len(obs) == len(sim):\n",
    "        sorted_obs = np.sort(obs)\n",
    "        sorted_sim = np.sort(sim)\n",
    "        return np.mean(np.abs(sorted_obs - sorted_sim))\n",
    "    else:\n",
    "        # fallback to scipy implementation if different sizes\n",
    "        from scipy.stats import wasserstein_distance as ws\n",
    "        return ws(obs, sim)\n",
    "\n",
    "# Common to all examples\n",
    "def gaussian_kernel(sq_distances, sigma):\n",
    "    return np.exp(-sq_distances / (2 * sigma))\n",
    "\n",
    "# Common to all examples\n",
    "def maximum_mean_discrepancy(obs, sim, obs_sq_dist=None, sigma=None):\n",
    "    if obs_sq_dist is None:\n",
    "        obs_sq_dist = pdist(obs.reshape(-1,1), 'sqeuclidean')\n",
    "    if sigma is None:\n",
    "        sigma = np.median(obs_sq_dist) ** 0.5\n",
    "    sim_sq_dist = pdist(sim.reshape(-1,1), 'sqeuclidean')\n",
    "    mixed_sq_dist = cdist(obs.reshape(-1,1), sim.reshape(-1,1), 'sqeuclidean')\n",
    "    k_xx = np.mean(gaussian_kernel(obs_sq_dist, sigma))\n",
    "    k_yy = np.mean(gaussian_kernel(sim_sq_dist, sigma))\n",
    "    k_xy = np.mean(gaussian_kernel(mixed_sq_dist, sigma))\n",
    "    return k_xx + k_yy - 2 * k_xy\n",
    "\n",
    "# Function specific to the exponential family example for ABC-Stat\n",
    "def stat_distance(observed_data, simulated_data):\n",
    "    log_observed = np.log(observed_data)\n",
    "    observed_stats = np.array([\n",
    "        np.sum(observed_data),\n",
    "        np.sum(log_observed),\n",
    "        np.sum(log_observed**2)\n",
    "    ])\n",
    "    \n",
    "    log_simulated = np.log(simulated_data)\n",
    "    simulated_stats = np.array([\n",
    "        np.sum(simulated_data),\n",
    "        np.sum(log_simulated),\n",
    "        np.sum(log_simulated**2)\n",
    "    ])\n",
    "    \n",
    "    return np.linalg.norm(observed_stats - simulated_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0497f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate simulated datasets from the three models in the exponential family example. We simule 1/3 of datasets from each mdoel. \n",
    "def simulate_datasets(n_sim=10**3, sample_size=100):\n",
    "    third = n_sim // 3\n",
    "\n",
    "    # Model 1: Exponential(θ), θ ~ Exponential(1) \n",
    "    theta0 = np.random.exponential(scale=1.0, size=third)\n",
    "    sim0 = np.array([np.random.exponential(scale=1/theta, size=sample_size) for theta in theta0])\n",
    "    models0 = np.zeros(third, dtype=int)\n",
    "\n",
    "    # Model 2: LogNormal(θ, 1), θ ~ N(0,1)\n",
    "    theta1 = np.random.normal(loc=0, scale=1, size=third)\n",
    "    sim1 = np.array([np.random.lognormal(mean=theta, sigma=1, size=sample_size) for theta in theta1])\n",
    "    models1 = np.ones(third, dtype=int)\n",
    "\n",
    "    # Model 3: Gamma(2, θ), θ ~ Exponential(1)\n",
    "    theta2 = np.random.exponential(scale=1.0, size=third)\n",
    "    sim2 = np.array([np.random.gamma(shape=2, scale=1/theta, size=sample_size) for theta in theta2])\n",
    "    models2 = np.full(third, 2, dtype=int)\n",
    "\n",
    "    # Combine all datasets\n",
    "    sims = np.vstack((sim0, sim1, sim2))\n",
    "    thetas = np.concatenate((theta0, theta1, theta2))\n",
    "    models = np.concatenate((models0, models1, models2))\n",
    "\n",
    "    return sims, thetas, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "003ea820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distances for one observed sample\n",
    "def compute_distances(observed_sample, sims):\n",
    "    n_sim = sims.shape[0]\n",
    "    sample_size = len(observed_sample)\n",
    "\n",
    "    # Take log of observed data: this is to use in case you want to compute ABC-MMD and ABC-Wass on log-transformed data\n",
    "    # log_obs = np.log(observed_sample)\n",
    "\n",
    "    # Precompute squared distances and sigma for MMD\n",
    "    obs_sq_dist = pdist(observed_sample.reshape(-1,1), 'sqeuclidean')\n",
    "    sigma = np.median(obs_sq_dist) ** 0.5\n",
    "    \n",
    "    distances_cvm = np.zeros(n_sim)\n",
    "    distances_wass = np.zeros(n_sim)\n",
    "    distances_mmd = np.zeros(n_sim)\n",
    "    distances_stat = np.zeros(n_sim)\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        sim_sample = sims[i]\n",
    "        distances_cvm[i] = cramer_von_mises_distance(observed_sample, sim_sample)\n",
    "        distances_wass[i] = wasserstein_distance(observed_sample, sim_sample)\n",
    "        distances_mmd[i] = maximum_mean_discrepancy(observed_sample, sim_sample, obs_sq_dist, sigma)\n",
    "        #distances_wass[i] = wasserstein_distance(log_obs, log_sim) # this is to use in case you want to compute ABC-MMD and ABC-Wass on log-transformed data\n",
    "        #distances_mmd[i] = maximum_mean_discrepancy(log_obs, log_sim, obs_sq_dist, sigma) # this is to use in case you want to compute ABC-MMD and ABC-Wass on log-transformed data\n",
    "        distances_stat[i] = stat_distance(observed_sample, sim_sample)\n",
    "    \n",
    "    return distances_cvm, distances_mmd, distances_wass, distances_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99130949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract results relative to the q% percentile of the distances\n",
    "def summarize_percentile(thetas, models, distances, percentile):\n",
    "    n = len(distances)\n",
    "    k = max(1, round(n * percentile / 100))\n",
    "    indices = np.argsort(distances)[:k]\n",
    "\n",
    "    selected_thetas = thetas[indices]\n",
    "    selected_models = models[indices]\n",
    "\n",
    "    model_probs = {}\n",
    "    theta_means = {}\n",
    "\n",
    "    for m in range(3):  \n",
    "        mask = selected_models == m\n",
    "        model_probs[m] = np.mean(mask)  \n",
    "        if np.any(mask):\n",
    "            theta_means[m] = np.mean(selected_thetas[mask])  \n",
    "        else:\n",
    "            theta_means[m] = np.nan  \n",
    "\n",
    "    return model_probs, theta_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24747310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ABC for one observed dataset\n",
    "def run_abc_for_one_observed(args):\n",
    "    observed_sample, sims, thetas, models, percentiles = args\n",
    "\n",
    "    # Compute distances\n",
    "    dist_cvm, dist_mmd, dist_wass, dist_stat = compute_distances(observed_sample, sims)\n",
    "\n",
    "    results = {}\n",
    "    for dist_enum, dist_array in zip(Distance, [dist_cvm, dist_mmd, dist_wass, dist_stat]):\n",
    "        dist_name = DISTANCE_LABELS[dist_enum]\n",
    "        results[dist_name] = {\n",
    "            'model_probs': [],  \n",
    "            'theta_means': []   \n",
    "        }\n",
    "\n",
    "        for perc in percentiles:\n",
    "            model_probs, theta_means = summarize_percentile(thetas, models, dist_array, perc)\n",
    "            results[dist_name]['model_probs'].append(model_probs)\n",
    "            results[dist_name]['theta_means'].append(theta_means)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb85cbb-5347-45d0-af3b-ed4b538b3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    sample_size = 100\n",
    "    n_sim = 10**6\n",
    "    n_observed = 100\n",
    "    percentiles = [0.1, 0.05, 0.01]  # Change for the percentiles you want\n",
    "\n",
    "    print(\"Simulating datasets...\")\n",
    "    sims, thetas, models = simulate_datasets(n_sim=n_sim, sample_size=sample_size)\n",
    "\n",
    "    print(f\"Simulating {n_observed} observed datasets...\")\n",
    "    observed_datasets = [np.random.exponential(scale=2.0, size=sample_size) for _ in range(n_observed)] # This is simulation from model M1 (Exponential(theta), you can change for other models\n",
    "\n",
    "    # Prepare arguments for parallel ABC\n",
    "    args_list = [(obs, sims, thetas, models, percentiles) for obs in observed_datasets]\n",
    "\n",
    "    print(f\"Starting parallel ABC with {cpu_count()} cores...\")\n",
    "    with Pool() as pool:\n",
    "        all_results = pool.map(run_abc_for_one_observed, args_list)\n",
    "\n",
    "    # Aggregate results\n",
    "    distance_names = list(DISTANCE_LABELS.values())\n",
    "    n_dist = len(distance_names)\n",
    "    n_perc = len(percentiles)\n",
    "    n_models = 3\n",
    "\n",
    "    model_probs_summary = np.zeros((n_observed, n_dist, n_perc, n_models))\n",
    "    theta_means_summary = np.zeros((n_observed, n_dist, n_perc, n_models))\n",
    "\n",
    "    for i, res in enumerate(all_results):\n",
    "        for d_idx, dist_name in enumerate(distance_names):\n",
    "            for p_idx in range(n_perc):\n",
    "                model_probs = res[dist_name]['model_probs'][p_idx]\n",
    "                theta_means = res[dist_name]['theta_means'][p_idx]\n",
    "                for m in range(n_models):\n",
    "                    model_probs_summary[i, d_idx, p_idx, m] = model_probs.get(m, 0.0)\n",
    "                    theta_means_summary[i, d_idx, p_idx, m] = theta_means.get(m, np.nan)\n",
    "\n",
    "    # Save results\n",
    "    np.savez('expo_family_ex_expo.npz',\n",
    "             model_probs=model_probs_summary,\n",
    "             theta_means=theta_means_summary,\n",
    "             percentiles=percentiles,\n",
    "             distance_names=distance_names,\n",
    "             model_labels=[\"Expo\", \"LogN\", \"Gamma\"])\n",
    "\n",
    "    print(\"ABC summaries saved to expo_family_ex_expo.npz\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ddb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
